{
  "cells": [
    {
      "cell_type": "raw",
      "id": "379bd191",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Project Report: Reddit Cryptocurrency Sentiment Analysis\"\n",
        "author: \"Wenbo Liu (wl2939), Lilly Loghmani (lql2103), Yixin Xiao, Thomas Bordino\"\n",
        "date: \"2025/2/19\"\n",
        "format: html\n",
        "execute:\n",
        "  eval: false\n",
        "  echo: true\n",
        "  warning: false\n",
        "  error: false\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca05f09c",
      "metadata": {},
      "source": [
        "# **1. Introduction**\n",
        "\n",
        "## **Project Overview**\n",
        "\n",
        "This project aims to analyze sentiment trends in Reddit cryptocurrency discussions. The goal is to collect, clean, preprocess, and analyze textual and numerical data from Reddit posts, focusing on Bitcoin-related discussions. The final analysis highlights patterns in engagement metrics (upvotes, comments) and explores their relationship with sentiment and time-based features.\n",
        "\n",
        "## **Data Source**\n",
        "\n",
        "The data is collected from the **r/cryptocurrency** subreddit using the **Reddit API (praw)**. The dataset contains metadata, including: - **Post Title & Content** - **Upvotes & Comments** - **Post Creation Time** - **Post URL**\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "# **2. Data Acquisition**\n",
        "\n",
        "## **Methodology**\n",
        "\n",
        "We used the `praw` library to fetch Reddit posts related to Bitcoin using the `subreddit.search()` function. The search query was set to \"Bitcoin\" to ensure relevance.\n",
        "\n",
        "## **Code Implementation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddca01f5",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"your_client_id\",\n",
        "    client_secret=\"your_client_secret\",\n",
        "    user_agent=\"CryptoSentimentApp\"\n",
        ")\n",
        "\n",
        "def fetch_reddit_posts(coin, num_posts):\n",
        "    subreddit = reddit.subreddit(\"cryptocurrency\")\n",
        "    posts_data = []\n",
        "    for post in subreddit.search(coin, limit=num_posts):\n",
        "        posts_data.append([\n",
        "            post.id, post.title, post.selftext, post.score, post.num_comments, post.url, post.created_utc\n",
        "        ])\n",
        "    df = pd.DataFrame(posts_data, columns=[\"Post_ID\", \"Title\", \"Content\", \"Upvotes\", \"Comments\", \"URL\", \"Timestamp\"])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3e10e1a",
      "metadata": {},
      "source": [
        "## **Dataset Sample**\n",
        "\n",
        "| Post_ID | Title                  | Upvotes | Comments | Timestamp  |\n",
        "|---------|------------------------|---------|----------|------------|\n",
        "| 1gqafju | Bitcoin cycle analysis | 3577    | 701      | 2024-01-01 |\n",
        "| 1h6yoqp | Bitcoin hits 100K      | 19972   | 342      | 2024-01-02 |\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "# **3. Data Cleaning & Preprocessing**\n",
        "\n",
        "## **Cleaning Steps**\n",
        "\n",
        "-   **Convert timestamps to datetime format**\n",
        "-   **Remove special characters & URLs** from text\n",
        "-   **Handle missing values (`content` field filled with \"No content\")**\n",
        "-   **Remove duplicate posts based on URLs**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96f7d372",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def clean_reddit_data(df):\n",
        "    df = df.copy()\n",
        "    df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
        "    df.drop_duplicates(subset=[\"url\"], inplace=True)\n",
        "    df[\"content\"].fillna(\"No content\", inplace=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "741fdf31",
      "metadata": {},
      "source": [
        "## **Preprocessing Steps**\n",
        "\n",
        "-   **Feature scaling (Log Transform for Upvotes & Comments)**\n",
        "-   **Extract time-based features (Hour, Day, Weekend Flag)**\n",
        "-   **Categorical encoding for `content`**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb2a887d",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def preprocess_data(df):\n",
        "    df = df.copy()\n",
        "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "    df['hour_of_day'] = df['timestamp'].dt.hour\n",
        "    df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
        "    df['log_upvotes'] = np.log1p(df['upvotes'])\n",
        "    df['log_comments'] = np.log1p(df['comments'])\n",
        "    scaler = StandardScaler()\n",
        "    df[['upvotes', 'comments']] = scaler.fit_transform(df[['upvotes', 'comments']])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cafeabd2",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# **4. Exploratory Data Analysis (EDA)**\n",
        "\n",
        "## **Key Insights from Visualizations**\n",
        "\n",
        "-   **Upvotes & comments have a right-skewed distribution.**\n",
        "-   **Weekday vs. Weekend engagement shows higher upvotes on weekends.**\n",
        "-   **Correlation between upvotes and comments is positive.**\n",
        "\n",
        "## **Visualization: Upvotes Distribution**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf9b277c",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.histplot(df['upvotes'], bins=30, kde=True, color='blue')\n",
        "plt.title(\"Distribution of Upvotes\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbc6d843",
      "metadata": {},
      "source": [
        "![](Distribution_upvotes.png)\n",
        "\n",
        "## **Visualization: Comments Distribution**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5afbb0",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.histplot(df['comments'], bins=30, kde=True, color='blue')\n",
        "plt.title(\"Distribution of Comments\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e7ee85f",
      "metadata": {},
      "source": [
        "![](Distribution_comments.png)\n",
        "\n",
        "\n",
        "## **Visualization: Comments And Upvotes**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19630021",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.scatterplot(x='upvotes', y='comments', data=df, color='red')\n",
        "plt.title(\"Upvotes vs. Comments\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86256fe9",
      "metadata": {},
      "source": [
        "![](comments_upvotes.png)\n",
        "\n",
        "\n",
        "## **Visualization: Correlation Heatmap**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "871418e7",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1d9b126",
      "metadata": {},
      "source": [
        "![](corr.png)\n",
        "\n",
        "## **Visualization: Upvotes over Time**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2d675c1",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "df['date'] = df['timestamp'].dt.date\n",
        "df.groupby('date')['upvotes'].sum().plot(figsize=(10, 5))\n",
        "plt.title(\"Total Upvotes Over Time\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Total Upvotes\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5f4b991",
      "metadata": {},
      "source": [
        "![](upvotes_time.png)\n",
        "\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "# **5. Feature Engineering**\n",
        "\n",
        "## **Added Features**\n",
        "\n",
        "| Feature                   | Description                                                         |\n",
        "|------------------------------|------------------------------------------|\n",
        "| `log_upvotes`             | Log transformation of upvotes because of right skewed distribution  |\n",
        "| `log_comments`            | Log transformation of comments because of right skewed distribution |\n",
        "| `title_len`               | Number of words in post title                                       |\n",
        "| `content_len`             | Number of words in post content                                     |\n",
        "| `is_working_hours`        | Whether the post was made during business hours (9AM - 5PM)         |\n",
        "| `engagement_score`        | Weighted score of upvotes & comments                                |\n",
        "| `upvote_to_comment_ratio` | Ratio of upvotes to comments                                        |\n",
        "| `has_bitcoin`             | Whether \"Bitcoin\" appears in the title                              |\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "![](dist_engage.png)\n",
        "![](engage_day.png)\n",
        "![](corr_engage.png)\n",
        "\n",
        "\n",
        "# **6. Conclusion & Future Work**\n",
        "\n",
        "## **Findings**\n",
        "\n",
        "-   **Sentiment polarity influences engagement (higher upvotes for positive sentiment).**\n",
        "-   **Posts with \"Bitcoin\" in the title tend to receive higher upvotes.**\n",
        "-   **Weekends show higher engagement.**\n",
        "\n",
        "## **Next Steps**\n",
        "\n",
        "-   **Apply NLP techniques (TF-IDF, LLM sentiment analysis).**\n",
        "-   **Build predictive models for Bitcoin price movement based on Reddit sentiment.**\n",
        "-   **Experiment with fine-tuned LLMs for finance-specific sentiment classification.**\n",
        "\n",
        "**This report summarizes the entire process, from data collection to analysis. The next phase will explore predictive modeling using the cleaned dataset.**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
