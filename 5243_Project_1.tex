% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Project Report: Reddit Cryptocurrency Sentiment Analysis},
  pdfauthor={Wenbo Liu (wl2939)},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Project Report: Reddit Cryptocurrency Sentiment Analysis}
\author{Wenbo Liu (wl2939)}
\date{2025-02-19}

\begin{document}
\maketitle

\section{\texorpdfstring{\textbf{1.
Introduction}}{1. Introduction}}\label{introduction}

\subsection{\texorpdfstring{\textbf{Project
Overview}}{Project Overview}}\label{project-overview}

This project aims to analyze sentiment trends in Reddit cryptocurrency
discussions. The goal is to collect, clean, preprocess, and analyze
textual and numerical data from Reddit posts, focusing on
Bitcoin-related discussions. The final analysis highlights patterns in
engagement metrics (upvotes, comments) and explores their relationship
with sentiment and time-based features.

\subsection{\texorpdfstring{\textbf{Data
Source}}{Data Source}}\label{data-source}

The data is collected from the \textbf{r/cryptocurrency} subreddit using
the \textbf{Reddit API (praw)}. The dataset contains metadata,
including: - \textbf{Post Title \& Content} - \textbf{Upvotes \&
Comments} - \textbf{Post Creation Time} - \textbf{Post URL}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{\texorpdfstring{\textbf{2. Data
Acquisition}}{2. Data Acquisition}}\label{data-acquisition}

\subsection{\texorpdfstring{\textbf{Methodology}}{Methodology}}\label{methodology}

We used the \texttt{praw} library to fetch Reddit posts related to
Bitcoin using the \texttt{subreddit.search()} function. The search query
was set to ``Bitcoin'' to ensure relevance.

\subsection{\texorpdfstring{\textbf{Code
Implementation}}{Code Implementation}}\label{code-implementation}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ praw}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\NormalTok{reddit }\OperatorTok{=}\NormalTok{ praw.Reddit(}
\NormalTok{    client\_id}\OperatorTok{=}\StringTok{"your\_client\_id"}\NormalTok{,}
\NormalTok{    client\_secret}\OperatorTok{=}\StringTok{"your\_client\_secret"}\NormalTok{,}
\NormalTok{    user\_agent}\OperatorTok{=}\StringTok{"CryptoSentimentApp"}
\NormalTok{)}

\KeywordTok{def}\NormalTok{ fetch\_reddit\_posts(coin, num\_posts):}
\NormalTok{    subreddit }\OperatorTok{=}\NormalTok{ reddit.subreddit(}\StringTok{"cryptocurrency"}\NormalTok{)}
\NormalTok{    posts\_data }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ post }\KeywordTok{in}\NormalTok{ subreddit.search(coin, limit}\OperatorTok{=}\NormalTok{num\_posts):}
\NormalTok{        posts\_data.append([}
\NormalTok{            post.}\BuiltInTok{id}\NormalTok{, post.title, post.selftext, post.score, post.num\_comments, post.url, post.created\_utc}
\NormalTok{        ])}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.DataFrame(posts\_data, columns}\OperatorTok{=}\NormalTok{[}\StringTok{"Post\_ID"}\NormalTok{, }\StringTok{"Title"}\NormalTok{, }\StringTok{"Content"}\NormalTok{, }\StringTok{"Upvotes"}\NormalTok{, }\StringTok{"Comments"}\NormalTok{, }\StringTok{"URL"}\NormalTok{, }\StringTok{"Timestamp"}\NormalTok{])}
    \ControlFlowTok{return}\NormalTok{ df}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{\textbf{Dataset
Sample}}{Dataset Sample}}\label{dataset-sample}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Post\_ID & Title & Upvotes & Comments & Timestamp \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1gqafju & Bitcoin cycle analysis & 3577 & 701 & 2024-01-01 \\
1h6yoqp & Bitcoin hits 100K & 19972 & 342 & 2024-01-02 \\
\end{longtable}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{\texorpdfstring{\textbf{3. Data Cleaning \&
Preprocessing}}{3. Data Cleaning \& Preprocessing}}\label{data-cleaning-preprocessing}

\subsection{\texorpdfstring{\textbf{Cleaning
Steps}}{Cleaning Steps}}\label{cleaning-steps}

\begin{itemize}
\tightlist
\item
  \textbf{Convert timestamps to datetime format}
\item
  \textbf{Remove special characters \& URLs} from text
\item
  \textbf{Handle missing values (\texttt{content} field filled with ``No
  content'')}
\item
  \textbf{Remove duplicate posts based on URLs}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ clean\_reddit\_data(df):}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ df.copy()}
\NormalTok{    df.columns }\OperatorTok{=}\NormalTok{ df.columns.}\BuiltInTok{str}\NormalTok{.lower().}\BuiltInTok{str}\NormalTok{.replace(}\StringTok{" "}\NormalTok{, }\StringTok{"\_"}\NormalTok{)}
\NormalTok{    df[}\StringTok{"timestamp"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"timestamp"}\NormalTok{], unit}\OperatorTok{=}\StringTok{"s"}\NormalTok{)}
\NormalTok{    df.drop\_duplicates(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"url"}\NormalTok{], inplace}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    df[}\StringTok{"content"}\NormalTok{].fillna(}\StringTok{"No content"}\NormalTok{, inplace}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ df}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{\textbf{Preprocessing
Steps}}{Preprocessing Steps}}\label{preprocessing-steps}

\begin{itemize}
\tightlist
\item
  \textbf{Feature scaling (Log Transform for Upvotes \& Comments)}
\item
  \textbf{Extract time-based features (Hour, Day, Weekend Flag)}
\item
  \textbf{Categorical encoding for \texttt{content}}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}

\KeywordTok{def}\NormalTok{ preprocess\_data(df):}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ df.copy()}
\NormalTok{    df[}\StringTok{\textquotesingle{}day\_of\_week\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{\textquotesingle{}timestamp\textquotesingle{}}\NormalTok{].dt.dayofweek}
\NormalTok{    df[}\StringTok{\textquotesingle{}hour\_of\_day\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{\textquotesingle{}timestamp\textquotesingle{}}\NormalTok{].dt.hour}
\NormalTok{    df[}\StringTok{\textquotesingle{}is\_weekend\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{\textquotesingle{}day\_of\_week\textquotesingle{}}\NormalTok{].}\BuiltInTok{apply}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ x: }\DecValTok{1} \ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textgreater{}=} \DecValTok{5} \ControlFlowTok{else} \DecValTok{0}\NormalTok{)}
\NormalTok{    df[}\StringTok{\textquotesingle{}log\_upvotes\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log1p(df[}\StringTok{\textquotesingle{}upvotes\textquotesingle{}}\NormalTok{])}
\NormalTok{    df[}\StringTok{\textquotesingle{}log\_comments\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log1p(df[}\StringTok{\textquotesingle{}comments\textquotesingle{}}\NormalTok{])}
\NormalTok{    scaler }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{    df[[}\StringTok{\textquotesingle{}upvotes\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}comments\textquotesingle{}}\NormalTok{]] }\OperatorTok{=}\NormalTok{ scaler.fit\_transform(df[[}\StringTok{\textquotesingle{}upvotes\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}comments\textquotesingle{}}\NormalTok{]])}
    \ControlFlowTok{return}\NormalTok{ df}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{\texorpdfstring{\textbf{4. Exploratory Data Analysis
(EDA)}}{4. Exploratory Data Analysis (EDA)}}\label{exploratory-data-analysis-eda}

\subsection{\texorpdfstring{\textbf{Key Insights from
Visualizations}}{Key Insights from Visualizations}}\label{key-insights-from-visualizations}

\begin{itemize}
\tightlist
\item
  \textbf{Upvotes \& comments have a right-skewed distribution.}
\item
  \textbf{Weekday vs.~Weekend engagement shows higher upvotes on
  weekends.}
\item
  \textbf{Correlation between upvotes and comments is positive.}
\end{itemize}

\subsection{\texorpdfstring{\textbf{Visualization: Upvotes
Distribution}}{Visualization: Upvotes Distribution}}\label{visualization-upvotes-distribution}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ seaborn }\ImportTok{as}\NormalTok{ sns}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\NormalTok{sns.histplot(df[}\StringTok{\textquotesingle{}upvotes\textquotesingle{}}\NormalTok{], bins}\OperatorTok{=}\DecValTok{30}\NormalTok{, kde}\OperatorTok{=}\VariableTok{True}\NormalTok{, color}\OperatorTok{=}\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{"Distribution of Upvotes"}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{\textbf{Visualization: Correlation
Heatmap}}{Visualization: Correlation Heatmap}}\label{visualization-correlation-heatmap}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.heatmap(df.corr(numeric\_only}\OperatorTok{=}\VariableTok{True}\NormalTok{), annot}\OperatorTok{=}\VariableTok{True}\NormalTok{, cmap}\OperatorTok{=}\StringTok{\textquotesingle{}coolwarm\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{"Correlation Matrix"}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{\texorpdfstring{\textbf{5. Feature
Engineering}}{5. Feature Engineering}}\label{feature-engineering}

\subsection{\texorpdfstring{\textbf{Added
Features}}{Added Features}}\label{added-features}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.4167}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5833}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Feature
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{log\_upvotes} & Log transformation of upvotes because of right
skewed distribution \\
\texttt{log\_comments} & Log transformation of comments because of right
skewed distribution \\
\texttt{title\_len} & Number of words in post title \\
\texttt{content\_len} & Number of words in post content \\
\texttt{is\_working\_hours} & Whether the post was made during business
hours (9AM - 5PM) \\
\texttt{engagement\_score} & Weighted score of upvotes \& comments \\
\texttt{upvote\_to\_comment\_ratio} & Ratio of upvotes to comments \\
\texttt{has\_bitcoin} & Whether ``Bitcoin'' appears in the title \\
\end{longtable}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{\texorpdfstring{\textbf{6. Conclusion \& Future
Work}}{6. Conclusion \& Future Work}}\label{conclusion-future-work}

\subsection{\texorpdfstring{\textbf{Findings}}{Findings}}\label{findings}

\begin{itemize}
\tightlist
\item
  \textbf{Sentiment polarity influences engagement (higher upvotes for
  positive sentiment).}
\item
  \textbf{Posts with ``Bitcoin'' in the title tend to receive higher
  upvotes.}
\item
  \textbf{Weekends show higher engagement.}
\end{itemize}

\subsection{\texorpdfstring{\textbf{Next
Steps}}{Next Steps}}\label{next-steps}

\begin{itemize}
\tightlist
\item
  \textbf{Apply NLP techniques (TF-IDF, LLM sentiment analysis).}
\item
  \textbf{Build predictive models for Bitcoin price movement based on
  Reddit sentiment.}
\item
  \textbf{Experiment with fine-tuned LLMs for finance-specific sentiment
  classification.}
\end{itemize}

\textbf{This report summarizes the entire process, from data collection
to analysis. The next phase will explore predictive modeling using the
cleaned dataset.}



\end{document}
