{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Post_ID                                              Title  \\\n",
      "0  1gqafju  Bitcoin has followed a consistent 4-year cycle...   \n",
      "1  1iq3fe9         Me In 2009 Instead of Buying Bitcoin (BTC)   \n",
      "2  1h6yoqp  On February 9th 2011 Bitcoin first touched $1....   \n",
      "3  1ik2qgu  Explaining Bitcoin 12 Years Ago When It Was Wo...   \n",
      "4  1hbsf6a  This Anonymous guy received $50 worth of Bitco...   \n",
      "\n",
      "                        Content  Upvotes  Comments  \\\n",
      "0                                   3572       700   \n",
      "1                                  17764       309   \n",
      "2                                   7822       495   \n",
      "3                                   8419       293   \n",
      "4  Imagine hodling for 13 Years     7415       452   \n",
      "\n",
      "                                    URL     Timestamp  \n",
      "0  https://i.redd.it/95px1ns8in0e1.jpeg  1.731496e+09  \n",
      "1   https://i.redd.it/denbcysakbje1.png  1.739632e+09  \n",
      "2   https://i.redd.it/m7ll0go40y4e1.png  1.733366e+09  \n",
      "3   https://i.redd.it/hd0ul5cglrhe1.png  1.738955e+09  \n",
      "4  https://i.redd.it/ogcetnacr76e1.jpeg  1.733920e+09  \n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "# Reddit API Credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"_9aT35rxVcBiNC17_Al5_g\",\n",
    "    client_secret=\"tyas9JGsMfhm4Jhifg86JnvpHZHx6A\",\n",
    "    user_agent=\"CryptoSentimentApp\"\n",
    ")\n",
    "\n",
    "def fetch_reddit_posts(coin, num_posts):\n",
    "    \"\"\"\n",
    "    Fetches Reddit posts related to a cryptocurrency and returns data in a Pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - coin (str): The cryptocurrency to search for.\n",
    "    - num_posts (int): Number of posts to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing post details.\n",
    "    \"\"\"\n",
    "    subreddit = reddit.subreddit(\"cryptocurrency\")\n",
    "    query = coin.lower()  \n",
    "    \n",
    "    \n",
    "    posts_data = []\n",
    "    for post in subreddit.search(query, limit=num_posts):\n",
    "        posts_data.append([\n",
    "            post.id,\n",
    "            post.title,\n",
    "            post.selftext,  # Post content\n",
    "            post.score,  # Upvotes\n",
    "            post.num_comments,  # Number of comments\n",
    "            post.url,  # Post link\n",
    "            post.created_utc  # Timestamp\n",
    "        ])\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(posts_data, columns=[\"Post_ID\", \"Title\", \"Content\", \"Upvotes\", \"Comments\", \"URL\", \"Timestamp\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "df_bitcoin_100 = fetch_reddit_posts(\"Bitcoin\", 1000)\n",
    "print(df_bitcoin_100.head())\n",
    "df_bitcoin_100.to_csv('csv_bitcoin_100.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   post_id                                              title  \\\n",
      "0  1gqafju  bitcoin has followed a consistent 4year cycle ...   \n",
      "1  1iq3fe9           me in 2009 instead of buying bitcoin btc   \n",
      "2  1h6yoqp  on february 9th 2011 bitcoin first touched 1 l...   \n",
      "3  1ik2qgu  explaining bitcoin 12 years ago when it was wo...   \n",
      "4  1hbsf6a  this anonymous guy received 50 worth of bitcoi...   \n",
      "\n",
      "                        content  upvotes  comments  \\\n",
      "0                           NaN     3572       700   \n",
      "1                           NaN    17764       309   \n",
      "2                           NaN     7822       495   \n",
      "3                           NaN     8419       293   \n",
      "4  imagine hodling for 13 years     7415       452   \n",
      "\n",
      "                                    url           timestamp  \n",
      "0  https://i.redd.it/95px1ns8in0e1.jpeg 2024-11-13 11:04:46  \n",
      "1   https://i.redd.it/denbcysakbje1.png 2025-02-15 15:13:54  \n",
      "2   https://i.redd.it/m7ll0go40y4e1.png 2024-12-05 02:39:33  \n",
      "3   https://i.redd.it/hd0ul5cglrhe1.png 2025-02-07 19:00:56  \n",
      "4  https://i.redd.it/ogcetnacr76e1.jpeg 2024-12-11 12:32:03  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_reddit_data(df):\n",
    "    \"\"\"\n",
    "    Cleans Reddit dataset by fixing inconsistencies, formatting text, and removing duplicates.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Raw Reddit dataset\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Cleaned dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1️⃣ Fix Data Inconsistencies (Convert Timestamp, Standardize Column Names)\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.str.lower().str.replace(\" \", \"_\")  # Standardize column names\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")  # Convert UNIX timestamp to datetime\n",
    "    \n",
    "    # 2️⃣ Uniform Formatting (Lowercasing & Removing Special Characters)\n",
    "    def clean_text(text):\n",
    "        if isinstance(text, str):\n",
    "            text = text.lower()  # Convert to lowercase\n",
    "            text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "            text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove special characters\n",
    "            text = text.strip()  # Remove leading/trailing spaces\n",
    "        return text\n",
    "\n",
    "    df[\"title\"] = df[\"title\"].apply(clean_text)\n",
    "    df[\"content\"] = df[\"content\"].apply(clean_text)\n",
    "    \n",
    "    # 3️⃣ Remove Duplicates\n",
    "    df.drop_duplicates(subset=[\"title\"], inplace=True)  # Remove duplicate titles\n",
    "    df.drop_duplicates(subset=[\"url\"], inplace=True)  # Remove duplicate URLs\n",
    "\n",
    "    df = df.drop(columns=[\"unnamed:_0\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "df_bitcoin_100 = pd.read_csv('csv_bitcoin_100.csv')  # Load the dataset\n",
    "df_clean = clean_reddit_data(df_bitcoin_100)  # Clean the dataset\n",
    "print(df_clean.head())  # Display cleaned data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
